{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vcf(vcf_file):\n",
    "    \"\"\"\n",
    "    Parses a VCF file for variants, collects them and return a dictionary\n",
    "        variants[chrom] = set of (pos,ref,alt) for all PASS variants \n",
    "    \"\"\"\n",
    "    variants=defaultdict(set)\n",
    "    with open(vcf_file,'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            \n",
    "            #splitting line by tabs\n",
    "            cols=line.strip().split('\\t')\n",
    "\n",
    "            #vcf columns are arranged as follows: CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO, ...\n",
    "            chrom = cols[0]\n",
    "            pos = cols[1]\n",
    "            id = cols[2]\n",
    "            ref = cols[3]\n",
    "            alt = cols[4]\n",
    "            filt = cols[6]\n",
    "\n",
    "            if filt == \"PASS\":\n",
    "                variants[chrom].add((pos, ref, alt))\n",
    "    \n",
    "    return variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_vcfs(benchmark_vcf, query_vcf):\n",
    "    \"\"\"\n",
    "    Compare two VCF files (filtered by PASS) in terms of:\n",
    "        1)Number of variants per chromosome\n",
    "        2)For each chromosome:\n",
    "            -calculation of Precision (fraction of query variants that match benchmark variants) OR (true positives/(true positives+false positives))\n",
    "            -calculation of Recall (fraction of benchmark variants that are matched by query variants) OR (true positives/(true positives + false negatives))\n",
    "        3)Prints out summary statistics\n",
    "    \"\"\"\n",
    "    #compile statistics for output\n",
    "    output_lines=[]\n",
    "\n",
    "    #parsing each vcf file to get variants\n",
    "    benchmark_variants= parse_vcf(benchmark_vcf)\n",
    "    query_variants=parse_vcf(query_vcf)\n",
    "\n",
    "    #get chromosomes of benchmark\n",
    "    chroms=list(benchmark_variants.keys())\n",
    "\n",
    "    #summaries (for counting variants across all chromosomes)\n",
    "    total_variants_benchmark=0\n",
    "    total_variants_query=0\n",
    "    total_shared=0\n",
    "\n",
    "    #comapring variants in each chromosome\n",
    "    for chrom in chroms:\n",
    "        variant_set_benchmark=benchmark_variants.get(chrom)\n",
    "        variant_set_query=query_variants.get(chrom)\n",
    "        if variant_set_benchmark is None:\n",
    "            output_lines.append(f\"{benchmark_vcf} has no variants for {chrom}\")\n",
    "            continue\n",
    "        elif variant_set_query is None:\n",
    "            output_lines.append(f\"{query_vcf} has no variants for {chrom}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "    \n",
    "        shared=variant_set_benchmark.intersection(variant_set_query)\n",
    "        \n",
    "        count1=len(variant_set_benchmark)\n",
    "        count2=len(variant_set_query)\n",
    "        shared_count=len(shared)\n",
    "       \n",
    "        #updating summary counts\n",
    "        total_variants_benchmark += count1\n",
    "        total_variants_query +=count2\n",
    "        total_shared += shared_count\n",
    "        output_lines.append(f\"For {chrom}, precision is {shared_count/count2} & recall is {shared_count/count1}\")\n",
    "\n",
    "    #Grand summary\n",
    "    output_lines.append(\"Overall Summary\")\n",
    "    output_lines.append(\"--------------\")\n",
    "    output_lines.append(f\"The total no. of variants in {benchmark_vcf} is {total_variants_benchmark}\")\n",
    "    output_lines.append(f\"The total no. of variants in {query_vcf} is {total_variants_query}\")\n",
    "    output_lines.append(f\"The total no. of correct variant found is {total_shared}\")\n",
    "    output_lines.append(f\"{round(((total_variants_query-total_shared)/total_variants_query)*100,2)}% of variants called in long-reads Nanopore in this case are false\")\n",
    "    output_lines.append(f\"{round((total_shared/total_variants_query)*100,2)}% of variants called in long-reads Nanopore in this case are true\")\n",
    "\n",
    "    return \"\\n\".join(output_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nabil/clair3_work/run_2_HG005/HG005_benchmark.vcf\n",
      "/home/nabil/clair3_work/run_2_HG005/merge_output.vcf\n"
     ]
    }
   ],
   "source": [
    "#fethcing the VCF files to work with-- files are in clair3_work\n",
    "clair3_work_dir=os.path.expanduser(\"~/clair3_work/run_2_HG005\")\n",
    "query_dir=os.path.expanduser(\"~/clair3_work/run_2_HG005\")\n",
    "benchmark_vcf=glob.glob(os.path.join(clair3_work_dir,\"HG005_benchmark.vcf\"))[0]\n",
    "query_vcf=glob.glob(os.path.join(query_dir,\"merge_output.vcf\"))[0]\n",
    "print(benchmark_vcf)\n",
    "print(query_vcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For chr1, precision is 0.7846847534139547 & recall is 0.958255830016352\n",
      "For chr2, precision is 0.8460859942151019 & recall is 0.9602303086135422\n",
      "For chr3, precision is 0.824118291347207 & recall is 0.961945464175479\n",
      "For chr4, precision is 0.7939290378150093 & recall is 0.9639248811720534\n",
      "For chr5, precision is 0.8233861365355454 & recall is 0.9619708840902652\n",
      "For chr6, precision is 0.7640456126890056 & recall is 0.9617067332708918\n",
      "For chr7, precision is 0.8094234618018379 & recall is 0.9603810173630438\n",
      "For chr8, precision is 0.8310696165682442 & recall is 0.9635996296796343\n",
      "For chr9, precision is 0.7430055651579327 & recall is 0.95967469901686\n",
      "For chr10, precision is 0.8096021699038142 & recall is 0.9609317728598599\n",
      "For chr11, precision is 0.8262538964774506 & recall is 0.9645026783064982\n",
      "For chr12, precision is 0.8142287610983605 & recall is 0.9597596464755335\n",
      "For chr13, precision is 0.775136591492148 & recall is 0.9632507419881949\n",
      "For chr14, precision is 0.8233245116915101 & recall is 0.9594932092256218\n",
      "For chr15, precision is 0.7232762855663396 & recall is 0.9604704056984679\n",
      "For chr16, precision is 0.8089399763026327 & recall is 0.9584328428477269\n",
      "For chr17, precision is 0.7576941191756127 & recall is 0.9536692559280457\n",
      "For chr18, precision is 0.7604260198090923 & recall is 0.9623271506739157\n",
      "For chr19, precision is 0.7779811485117504 & recall is 0.9552906110283159\n",
      "For chr20, precision is 0.6097841590556269 & recall is 0.961147200934057\n",
      "For chr21, precision is 0.6501618328361998 & recall is 0.9637078567128236\n",
      "For chr22, precision is 0.5748333669965664 & recall is 0.95843067921113\n",
      "Overall Summary\n",
      "--------------\n",
      "The total no. of variants in /home/nabil/clair3_work/run_2_HG005/HG005_benchmark.vcf is 3832735\n",
      "The total no. of variants in /home/nabil/clair3_work/run_2_HG005/merge_output.vcf is 4675078\n",
      "The total no. of correct variant found is 3683074\n",
      "21.22% of variants called in long-reads Nanopore in this case are false\n",
      "78.78% of variants called in long-reads Nanopore in this case are true\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#processing\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHG0005_output.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 3\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(compare_vcfs(benchmark_vcf,query_vcf))\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not None"
     ]
    }
   ],
   "source": [
    "#processing\n",
    "with open('HG0005_output.txt','w') as file:\n",
    "    file.write(compare_vcfs(benchmark_vcf,query_vcf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
